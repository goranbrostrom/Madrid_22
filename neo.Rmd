---
title: "Neonatal models"
author: "Göran Broström"
date: "`r Sys.Date()`"
output:
  bookdown::pdf_document2:
    citation_package: natbib
    keep_tex: yes
    number_sections: yes
    toc: no
    toc_depth: 2
  bookdown::word_document2:
    toc: no
    toc_depth: 2
  bookdown::html_document2:
    number_sections: yes
    toc: yes
    toc_depth: 2
    toc_float: yes
citation_package: natbib
bibliography: bio.bib
titlepage: no
biblio-style: apalike
documentclass: article
fontsize: 11pt
header-includes:
- \usepackage{a4wide}    
- \usepackage[utf8]{inputenc}
- \usepackage{graphicx}
abstract: "The effect of extreme temperatures on neonatal mortality in the Umeå region 1895-1950 is studied as an example of how to do it with tabular, anonymised data."
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,comment = NA)
```

# Introduction

How to analyse table data with the same statistical models, e.e., *Cox regression*
as you are used to with individual, interval based data, is shown here. You need the 
**R** package *eha* [@eha; @ehar2] for easy conversion of individual data to tabular
suitable for survival analysis.

# Example: Neonatal mortality in Umeå/Skellefteå, 1895--1950

We use a data set for studying infant mortality from the *Demographic Database*,
Umeå University.

## Read data

Start by reading the prepared file and select a few columns, remove zero-length
spells, and put on reasonable row names:

```{r readdata}
infdat <- readRDS("data/infdat.rds")[, c("id", "enter", "exit", "event", 
                                         "sex", "socStatus", "illeg",  
                                         "parity", "cold", "week")]
## remove zero-length spells:
infdat <- infdat[infdat$exit > infdat$enter + 1.e-6, ] 
rownames(infdat) <- 1:NROW(infdat)
NROW(infdat)
length(unique(infdat$id))
head(infdat)
```

Then, cut the spells to fit into the first four weeks of life. Use the function 
*age.window* from the package *eha*.

```{r agecut}
library(eha)
neo <- age.window(infdat, c(0, 28 / 365))
```

## Transform time unit 'years' to 'days' and "round", down and up:

Note that the original data file measures time in *years*. For neonatal mortality,
a more convenient time unit is *days*, so we convert and round.

```{r transform}
neo$enter <- round(365 * neo$enter)
neo$exit <- round(365 * neo$exit)
neo <- neo[neo$exit > neo$enter, ] # Remove zero-length spells

dim(neo)
head(neo)
```


## Cleaning data

Since this is just an example showing how to analyse given data, we clean data in 
order to avoid discussions about missing values and other disturbances.

```{r clean}
neo <- neo[neo$parity > 0, ] # Remove missing = -1
neo$parity <- cut(neo$parity, c(0, 1.5, 3.5, 18.5), labels = c("1", "2-3", "4+"))
neo <- neo[!is.na(neo$socStatus), ] # Remove records with missing values
```

Next, *tabulate* data with the aid of the function *toTpch*, found in *eha*:

```{r tabulate}
tneo <- toTpch(Surv(enter, exit, event) ~  
                   sex + socStatus + illeg + parity + cold, 
               data = neo, cuts = 0:28)
dim(tneo)
head(tneo)
summary(tneo)
saveRDS(tneo, file = "t_data/tneo.rds")
```

Note how it works: For each combination of *socStatus*, *illeg*, *parity* *cold*
(*cold* is temperature above average minimum), and *age*, the number of deaths (*event*)
and the *exposure* time (in days) are calculated. Note that the tabulated data frame is 
a tenth in size compared to the original file, and it is also *anonymous*.

So, it should not be any problem with public distribution of the tabulated data. 

# The Cox regression model

On the original data frame, we can run an ordinary Cox regression, see Table 
\@ref(tab:coxreg).

```{r coxreg, results = 'asis'}
(system.time(fit.cr <- coxreg(Surv(enter, exit, event) ~ 
                                  sex + socStatus + illeg + parity + cold,
                 data = neo))) 
dr <- drop1(fit.cr, test = "Chisq")
ltx(fit.cr, dr = dr, label = "tab:coxreg", caption = "Cox regression.")
```

# The tabulated piecewise constant hazards (pch) model

On the tabulated data frame, we get, see Table \@ref(tab:tpchreg).

```{r tpchreg, results = 'asis'}
(system.time(fit.pch <- tpchreg(oe(event, exposure) ~ 
                                    sex + socStatus + illeg + parity + cold,
                                time = age, data = tneo)))
dr2 <- drop1(fit.pch, test = "Chisq")
ltx(fit.pch, dr = dr2, label = "tab:tpchreg", 
    caption = "Piecewise constant proportional hazards model.")
```

Almost identical results compared to Table \@ref(tab:coxreg). We can compare 
baseline cumulative hazards plots (Figure \@ref(fig:baseplots)):

```{r baseplots, fig.cap = "Comparison.", fig.height = 6}
op <- par(mfrow = c(2, 1), las = 1)
plot(fit.cr, main = "Cox regression")
plot(fit.pch, fn = "cum", main = "Pch regression")
par(op)
```
 
 Almost identical, disregarding differences in smoothness. An advantage with the 
 pch model is that we have access to an estimate of the baseline hazard function,
 see Figure \@ref(fig:haz).

```{r haz, fig.cap = "Baseline hazard function.",  fig.height = 4}
par(las = 1)
plot(fit.pch, fn = "haz")
abline(h = 0)
```
 
 
# "Logistic regression"

If, for some reason, it is desirable to use logistic regression as a proxy for Cox regression,
it is straightforward with the tabulated data.

```{r logistic}
fit.l <- glm(cbind(event, exposure - event) ~ 
                 sex + socStatus + illeg + parity + cold + age,
             family = binomial(link = "cloglog"), data = tneo)
coefficients(fit.l)[1:6]
drop1(fit.l, test = "Chisq")
```

Note the *cbind* and *link = "cloglog"*! Results are quite similar to previous ones, 
but estimation and plotting of baseline distributions are tedious.

However, starting with the non-tabulated data frame, everything is straightforward using
*eha::coxreg* with *method = "ml"* ("maximum likelihood"). Recommended for
the logistic regression approach with discrete time data.

# Effects of time transformation and tabular data.

As an example of time transformation, we study the *log-cube* transformation used by 
Bourgeouis-Pichat [@bp51a; @bp51b] in his study of endogeneous and exogeneous 
factors explaining infant mortality. It is given by

\begin{equation}
g(t) = \bigl(log(1 + t)\bigr)^3, \quad 0 \le t \le 365,
\end{equation}

where $t$ is measured in days.

So what happens if data are time-transformed before tabulation? Let us see:
First the transformation of the data frame *neo*:

```{r gtrans}
g <- function(t) (log(1 + t))^3
gneo <- neo
gneo$enter <- g(neo$enter)
gneo$exit <- g(neo$exit)
head(gneo)
```

Next tabulation: We need to transform the chosen cut points, if we want comparability, so

```{r tgneo}
tgneo <- toTpch(Surv(enter, exit, event) ~ 
                    sex + socStatus + illeg + parity + cold, 
               data = gneo, cuts = g(0:28))
head(tgneo)
#summary(tgneo)
```

Note the clumsy levels of the factor *age*. Not important. Let us try a "piecewise constant ..."

```{r tpchreg_g, results = 'asis'}
(system.time(fit.pch_g <- tpchreg(oe(event, exposure) ~ 
                                    sex + socStatus + illeg + parity + cold,
                                time = age, data = tgneo)))
dr2_g <- drop1(fit.pch_g, test = "Chisq")
ltx(fit.pch_g, dr = dr2_g, label = "tab:tpchreg_g", 
    caption = "Piecewise constant proportional hazards model with time transformation.")
```

Compare the Tables \@ref(tab:tpchreg) and \@ref(tab:tpchreg_g). Identical except for *TTR*
(Total Time at Risk). And graphs will be stretcehd.

```{r haz_g, fig.cap = "Baseline hazard function, transformed time.",  fig.height = 4}
par(las = 1)
plot(fit.pch_g, fn = "haz")
abline(h = 0)
```

We can spot how the transformation drives the the hazard function to *constant* 
over time, say after $ g(t) = 10$, that is, after around 8 days.
 